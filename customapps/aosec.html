<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MAESTRO AI Security Audit Platform</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        .gradient-bg {
            background: linear-gradient(-45deg, #667eea, #764ba2, #f093fb, #4facfe);
            background-size: 400% 400%;
            animation: gradient 15s ease infinite;
        }
        .glassmorphism {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .threat-card {
            transition: all 0.3s ease;
        }
        .threat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
        }
    </style>
</head>
<body class="gradient-bg min-h-screen">
    <div class="container mx-auto px-4 py-8">
        <!-- Header -->
        <header class="text-center mb-12">
            <h1 class="text-5xl font-bold text-white mb-4 drop-shadow-lg">
                üõ°Ô∏è MAESTRO AI Security Audit Platform
            </h1>
            <p class="text-xl text-white/90 drop-shadow">
                Multi-Agent Environment, Security, Threat, Risk, and Outcome Framework
            </p>
            <p class="text-sm text-white/80 mt-2">
                Integrated with OWASP AI Top 10 & MITRE ATLAS
            </p>
        </header>

        <!-- File Upload Section -->
        <div class="glassmorphism rounded-2xl p-8 mb-8 shadow-2xl">
            <h2 class="text-3xl font-bold text-white mb-6 flex items-center">
                <span class="mr-3">üìÅ</span> Upload System Architecture
            </h2>
            
            <div class="border-4 border-dashed border-white/40 rounded-xl p-8 text-center hover:border-white/60 transition-all cursor-pointer bg-white/5" id="dropZone">
                <input type="file" id="fileInput" multiple accept=".txt,.yml,.yaml,.json,.xml,.md,.py,.js,.ts,.jsx,.tsx,.java,.cpp,.c,.cs,.go,.rb,.php,.html,.css,.svg,.png,.jpg,.jpeg" class="hidden">
                <div class="text-white">
                    <svg class="mx-auto h-16 w-16 mb-4 opacity-80" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
                    </svg>
                    <p class="text-xl font-semibold mb-2">Drop files here or click to upload</p>
                    <p class="text-sm opacity-80">Supports: Text, Code (Python, JS, Java, etc.), YAML, JSON, XML, Diagrams (SVG, PNG, JPG)</p>
                </div>
            </div>

            <div id="fileList" class="mt-6 space-y-2"></div>

            <button id="analyzeBtn" class="mt-6 w-full bg-gradient-to-r from-purple-600 to-blue-600 text-white font-bold py-4 px-8 rounded-xl hover:from-purple-700 hover:to-blue-700 transition-all shadow-lg hover:shadow-xl disabled:opacity-50 disabled:cursor-not-allowed">
                üîç Analyze with MAESTRO Framework
            </button>
        </div>

        <!-- Framework Tabs -->
        <div class="glassmorphism rounded-2xl p-8 mb-8 shadow-2xl">
            <div class="flex border-b border-white/30 mb-6">
                <button class="tab-btn active px-6 py-3 font-semibold text-white border-b-4 border-purple-400 transition-all" data-tab="maestro">
                    MAESTRO Framework
                </button>
                <button class="tab-btn px-6 py-3 font-semibold text-white/70 hover:text-white border-b-4 border-transparent transition-all" data-tab="owasp">
                    OWASP AI Top 10
                </button>
                <button class="tab-btn px-6 py-3 font-semibold text-white/70 hover:text-white border-b-4 border-transparent transition-all" data-tab="mitre">
                    MITRE ATLAS
                </button>
            </div>

            <!-- MAESTRO Tab -->
            <div id="maestro-tab" class="tab-content">
                <h3 class="text-2xl font-bold text-white mb-4">MAESTRO Framework Components</h3>
                <div class="grid md:grid-cols-2 lg:grid-cols-3 gap-4">
                    <div class="threat-card bg-white/10 rounded-xl p-6 border border-white/20">
                        <div class="text-3xl mb-3">ü§ñ</div>
                        <h4 class="text-lg font-bold text-white mb-2">Multi-Agent</h4>
                        <p class="text-white/80 text-sm">Analyze interactions between AI agents, humans, and systems in complex environments</p>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-6 border border-white/20">
                        <div class="text-3xl mb-3">üåê</div>
                        <h4 class="text-lg font-bold text-white mb-2">Environment</h4>
                        <p class="text-white/80 text-sm">Assess deployment contexts, infrastructure, and operational boundaries</p>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-6 border border-white/20">
                        <div class="text-3xl mb-3">üîí</div>
                        <h4 class="text-lg font-bold text-white mb-2">Security</h4>
                        <p class="text-white/80 text-sm">Evaluate authentication, authorization, encryption, and access controls</p>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-6 border border-white/20">
                        <div class="text-3xl mb-3">‚ö†Ô∏è</div>
                        <h4 class="text-lg font-bold text-white mb-2">Threat</h4>
                        <p class="text-white/80 text-sm">Identify adversarial attacks, prompt injection, model poisoning</p>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-6 border border-white/20">
                        <div class="text-3xl mb-3">üìä</div>
                        <h4 class="text-lg font-bold text-white mb-2">Risk</h4>
                        <p class="text-white/80 text-sm">Quantify likelihood and impact of identified threats</p>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-6 border border-white/20">
                        <div class="text-3xl mb-3">üéØ</div>
                        <h4 class="text-lg font-bold text-white mb-2">Outcome</h4>
                        <p class="text-white/80 text-sm">Define security objectives and success metrics</p>
                    </div>
                </div>
            </div>

            <!-- OWASP AI Top 10 Tab -->
            <div id="owasp-tab" class="tab-content hidden">
                <h3 class="text-2xl font-bold text-white mb-4">OWASP AI Top 10 Vulnerabilities</h3>
                <div class="space-y-3">
                    <div class="threat-card bg-gradient-to-r from-red-500/20 to-red-600/20 rounded-xl p-5 border border-red-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM01: Prompt Injection</h4>
                        <p class="text-white/80 text-sm">Malicious inputs that manipulate LLM behavior and bypass safeguards</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-orange-500/20 to-orange-600/20 rounded-xl p-5 border border-orange-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM02: Insecure Output Handling</h4>
                        <p class="text-white/80 text-sm">Insufficient validation of LLM outputs leading to XSS, CSRF, SSRF, and code execution</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-yellow-500/20 to-yellow-600/20 rounded-xl p-5 border border-yellow-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM03: Training Data Poisoning</h4>
                        <p class="text-white/80 text-sm">Manipulation of training data to introduce vulnerabilities or biases</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-green-500/20 to-green-600/20 rounded-xl p-5 border border-green-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM04: Model Denial of Service</h4>
                        <p class="text-white/80 text-sm">Resource-heavy operations causing service degradation or high costs</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-blue-500/20 to-blue-600/20 rounded-xl p-5 border border-blue-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM05: Supply Chain Vulnerabilities</h4>
                        <p class="text-white/80 text-sm">Compromised components, data sets, or third-party dependencies</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-indigo-500/20 to-indigo-600/20 rounded-xl p-5 border border-indigo-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM06: Sensitive Information Disclosure</h4>
                        <p class="text-white/80 text-sm">Leakage of confidential data through model outputs</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-purple-500/20 to-purple-600/20 rounded-xl p-5 border border-purple-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM07: Insecure Plugin Design</h4>
                        <p class="text-white/80 text-sm">Inadequate access control and validation in LLM plugins</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-pink-500/20 to-pink-600/20 rounded-xl p-5 border border-pink-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM08: Excessive Agency</h4>
                        <p class="text-white/80 text-sm">LLM systems with too much autonomy or permissions</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-red-500/20 to-pink-600/20 rounded-xl p-5 border border-red-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM09: Overreliance</h4>
                        <p class="text-white/80 text-sm">Excessive dependence on LLM outputs without oversight</p>
                    </div>
                    <div class="threat-card bg-gradient-to-r from-gray-500/20 to-gray-600/20 rounded-xl p-5 border border-gray-400/30">
                        <h4 class="text-lg font-bold text-white mb-1">LLM10: Model Theft</h4>
                        <p class="text-white/80 text-sm">Unauthorized access to proprietary models via extraction or replication</p>
                    </div>
                </div>
            </div>

            <!-- MITRE ATLAS Tab -->
            <div id="mitre-tab" class="tab-content hidden">
                <h3 class="text-2xl font-bold text-white mb-4">MITRE ATLAS Threat Tactics</h3>
                <div class="grid md:grid-cols-2 gap-4">
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">üéØ Reconnaissance</h4>
                        <p class="text-white/80 text-sm mb-3">Gather information about ML systems and capabilities</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Discover ML artifacts</li>
                            <li>‚Ä¢ Identify ML model architecture</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">üîì Resource Development</h4>
                        <p class="text-white/80 text-sm mb-3">Establish resources for attacking ML systems</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Acquire ML attack capabilities</li>
                            <li>‚Ä¢ Develop adversarial data</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">üö™ Initial Access</h4>
                        <p class="text-white/80 text-sm mb-3">Gain entry into ML pipeline or system</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Supply chain compromise</li>
                            <li>‚Ä¢ Exploit public-facing applications</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">‚öôÔ∏è ML Model Access</h4>
                        <p class="text-white/80 text-sm mb-3">Obtain ML model for analysis or theft</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Model extraction via API</li>
                            <li>‚Ä¢ Physical access to model</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">üî¨ Execution</h4>
                        <p class="text-white/80 text-sm mb-3">Run malicious code in ML environment</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Command and scripting interpreter</li>
                            <li>‚Ä¢ User execution</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">‚è±Ô∏è Persistence</h4>
                        <p class="text-white/80 text-sm mb-3">Maintain presence in ML system</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Poison training data</li>
                            <li>‚Ä¢ Backdoor ML model</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">üé≠ Defense Evasion</h4>
                        <p class="text-white/80 text-sm mb-3">Avoid detection during attack</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Evade ML model detection</li>
                            <li>‚Ä¢ Obfuscate adversarial data</li>
                        </ul>
                    </div>
                    <div class="threat-card bg-white/10 rounded-xl p-5 border border-white/20">
                        <h4 class="text-lg font-bold text-white mb-2">üí• Impact</h4>
                        <p class="text-white/80 text-sm mb-3">Manipulate, disrupt, or destroy ML systems</p>
                        <ul class="text-white/70 text-xs space-y-1">
                            <li>‚Ä¢ Erode ML model integrity</li>
                            <li>‚Ä¢ Denial of ML service</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Analysis Results -->
        <div id="resultsSection" class="hidden glassmorphism rounded-2xl p-8 shadow-2xl">
            <h2 class="text-3xl font-bold text-white mb-6">üìã Analysis Results</h2>
            <div id="analysisResults" class="space-y-4"></div>
            
            <button id="exportBtn" class="mt-6 bg-gradient-to-r from-green-600 to-teal-600 text-white font-bold py-3 px-6 rounded-xl hover:from-green-700 hover:to-teal-700 transition-all shadow-lg">
                üì• Export Audit Report
            </button>
        </div>
    </div>

    <script>
        // State management
        let uploadedFiles = [];
        let analysisData = {};

        // DOM Elements
        const dropZone = document.getElementById('dropZone');
        const fileInput = document.getElementById('fileInput');
        const fileList = document.getElementById('fileList');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const resultsSection = document.getElementById('resultsSection');
        const analysisResults = document.getElementById('analysisResults');
        const exportBtn = document.getElementById('exportBtn');

        // Tab switching
        document.querySelectorAll('.tab-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                const tabName = btn.dataset.tab;
                
                // Update button styles
                document.querySelectorAll('.tab-btn').forEach(b => {
                    b.classList.remove('active', 'border-purple-400', 'text-white');
                    b.classList.add('text-white/70', 'border-transparent');
                });
                btn.classList.add('active', 'border-purple-400', 'text-white');
                btn.classList.remove('text-white/70', 'border-transparent');
                
                // Show selected tab content
                document.querySelectorAll('.tab-content').forEach(content => {
                    content.classList.add('hidden');
                });
                document.getElementById(`${tabName}-tab`).classList.remove('hidden');
            });
        });

        // File upload handling
        dropZone.addEventListener('click', () => fileInput.click());
        
        dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            dropZone.classList.add('border-white/80', 'bg-white/10');
        });
        
        dropZone.addEventListener('dragleave', () => {
            dropZone.classList.remove('border-white/80', 'bg-white/10');
        });
        
        dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            dropZone.classList.remove('border-white/80', 'bg-white/10');
            handleFiles(e.dataTransfer.files);
        });
        
        fileInput.addEventListener('change', (e) => {
            handleFiles(e.target.files);
        });

        function handleFiles(files) {
            uploadedFiles = [...uploadedFiles, ...Array.from(files)];
            displayFiles();
            analyzeBtn.disabled = false;
        }

        function displayFiles() {
            fileList.innerHTML = uploadedFiles.map((file, index) => `
                <div class="flex items-center justify-between bg-white/10 rounded-lg p-4 border border-white/20">
                    <div class="flex items-center space-x-3">
                        <span class="text-2xl">${getFileIcon(file.name)}</span>
                        <div>
                            <p class="text-white font-semibold">${file.name}</p>
                            <p class="text-white/60 text-sm">${formatFileSize(file.size)}</p>
                        </div>
                    </div>
                    <button onclick="removeFile(${index})" class="text-red-400 hover:text-red-300 font-bold">‚úï</button>
                </div>
            `).join('');
        }

        function removeFile(index) {
            uploadedFiles.splice(index, 1);
            displayFiles();
            if (uploadedFiles.length === 0) {
                analyzeBtn.disabled = true;
            }
        }

        function getFileIcon(filename) {
            const ext = filename.split('.').pop().toLowerCase();
            const iconMap = {
                'py': 'üêç', 'js': 'üìú', 'ts': 'üìò', 'java': '‚òï',
                'yml': '‚öôÔ∏è', 'yaml': '‚öôÔ∏è', 'json': 'üìã', 'xml': 'üìÑ',
                'txt': 'üìù', 'md': 'üìñ', 'svg': 'üé®',
                'png': 'üñºÔ∏è', 'jpg': 'üñºÔ∏è', 'jpeg': 'üñºÔ∏è'
            };
            return iconMap[ext] || 'üìÑ';
        }

        function formatFileSize(bytes) {
            if (bytes < 1024) return bytes + ' B';
            if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
            return (bytes / (1024 * 1024)).toFixed(1) + ' MB';
        }

        // Analysis function
        analyzeBtn.addEventListener('click', async () => {
            analyzeBtn.disabled = true;
            analyzeBtn.innerHTML = 'üîÑ Analyzing...';
            
            // Simulate analysis with progress
            await new Promise(resolve => setTimeout(resolve, 2000));
            
            // Read file contents
            const fileContents = await Promise.all(
                uploadedFiles.map(file => readFileContent(file))
            );
            
            // Perform analysis
            performAnalysis(fileContents);
            
            analyzeBtn.innerHTML = '‚úÖ Analysis Complete';
            resultsSection.classList.remove('hidden');
            resultsSection.scrollIntoView({ behavior: 'smooth' });
            
            setTimeout(() => {
                analyzeBtn.innerHTML = 'üîç Analyze with MAESTRO Framework';
                analyzeBtn.disabled = false;
            }, 2000);
        });

        async function readFileContent(file) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onload = (e) => {
                    resolve({
                        name: file.name,
                        type: file.type,
                        content: e.target.result,
                        size: file.size
                    });
                };
                
                if (file.type.startsWith('image/')) {
                    reader.readAsDataURL(file);
                } else {
                    reader.readAsText(file);
                }
            });
        }

        function performAnalysis(fileContents) {
            analysisData = {
                timestamp: new Date().toISOString(),
                files: fileContents.length,
                findings: []
            };

            // Analyze content for security issues
            fileContents.forEach(file => {
                const findings = analyzeFile(file);
                analysisData.findings.push(...findings);
            });

            displayResults();
        }

        function analyzeFile(file) {
            const findings = [];
            const content = file.content.toLowerCase();

            // Check for common security patterns
            const patterns = {
                'Potential Prompt Injection Risk': ['eval(', 'exec(', 'system(', 'shell_exec'],
                'Hardcoded Credentials': ['password', 'api_key', 'secret', 'token'],
                'Insecure Data Handling': ['pickle.loads', 'yaml.load(', 'json.loads'],
                'Missing Input Validation': ['request.args', 'request.form', 'input('],
                'Potential Model Access': ['model.load', 'torch.load', 'keras.load'],
                'External API Calls': ['requests.', 'urllib', 'http.client'],
            };

            Object.entries(patterns).forEach(([threat, keywords]) => {
                keywords.forEach(keyword => {
                    if (content.includes(keyword)) {
                        findings.push({
                            file: file.name,
                            threat: threat,
                            severity: calculateSeverity(threat),
                            framework: categorizeByFramework(threat),
                            detail: `Found: "${keyword}" in ${file.name}`
                        });
                    }
                });
            });

            return findings;
        }

        function calculateSeverity(threat) {
            const highRisk = ['Prompt Injection', 'Credentials', 'Model Access'];
            const mediumRisk = ['Input Validation', 'Data Handling'];
            
            if (highRisk.some(risk => threat.includes(risk))) return 'HIGH';
            if (mediumRisk.some(risk => threat.includes(risk))) return 'MEDIUM';
            return 'LOW';
        }

        function categorizeByFramework(threat) {
            if (threat.includes('Prompt Injection')) return ['OWASP: LLM01', 'MITRE: AML.T0051'];
            if (threat.includes('Input Validation')) return ['OWASP: LLM02', 'MAESTRO: Security'];
            if (threat.includes('Model')) return ['OWASP: LLM10', 'MITRE: AML.T0040'];
            if (threat.includes('Credentials')) return ['OWASP: LLM06', 'MAESTRO: Security'];
            return ['MAESTRO: Threat'];
        }

        function displayResults() {
            const severityCounts = {
                HIGH: analysisData.findings.filter(f => f.severity === 'HIGH').length,
                MEDIUM: analysisData.findings.filter(f => f.severity === 'MEDIUM').length,
                LOW: analysisData.findings.filter(f => f.severity === 'LOW').length
            };

            analysisResults.innerHTML = `
                <!-- Summary Cards -->
                <div class="grid grid-cols-1 md:grid-cols-4 gap-4 mb-6">
                    <div class="bg-gradient-to-br from-blue-500/30 to-blue-600/30 rounded-xl p-6 border border-blue-400/30">
                        <div class="text-3xl font-bold text-white">${analysisData.files}</div>
                        <div class="text-white/80 text-sm">Files Analyzed</div>
                    </div>
                    <div class="bg-gradient-to-br from-red-500/30 to-red-600/30 rounded-xl p-6 border border-red-400/30">
                        <div class="text-3xl font-bold text-white">${severityCounts.HIGH}</div>
                        <div class="text-white/80 text-sm">High Severity</div>
                    </div>
                    <div class="bg-gradient-to-br from-orange-500/30 to-orange-600/30 rounded-xl p-6 border border-orange-400/30">
                        <div class="text-3xl font-bold text-white">${severityCounts.MEDIUM}</div>
                        <div class="text-white/80 text-sm">Medium Severity</div>
                    </div>
                    <div class="bg-gradient-to-br from-yellow-500/30 to-yellow-600/30 rounded-xl p-6 border border-yellow-400/30">
                        <div class="text-3xl font-bold text-white">${severityCounts.LOW}</div>
                        <div class="text-white/80 text-sm">Low Severity</div>
                    </div>
                </div>

                <!-- Findings List -->
                <div class="space-y-3">
                    ${analysisData.findings.length > 0 ? 
                        analysisData.findings.map(finding => `
                            <div class="bg-white/10 rounded-xl p-5 border border-white/20">
                                <div class="flex items-start justify-between mb-3">
                                    <h4 class="text-lg font-bold text-white">${finding.threat}</h4>
                                    <span class="px-3 py-1 rounded-full text-xs font-bold ${
                                        finding.severity === 'HIGH' ? 'bg-red-500' :
                                        finding.severity === 'MEDIUM' ? 'bg-orange-500' :
                                        'bg-yellow-500'
                                    } text-white">${finding.severity}</span>
                                </div>
                                <p class="text-white/70 text-sm mb-2">${finding.detail}</p>
                                <div class="flex flex-wrap gap-2">
                                    ${finding.framework.map(fw => `
                                        <span class="px-2 py-1 bg-purple-500/30 rounded text-xs text-white border border-purple-400/30">
                                            ${fw}
                                        </span>
                                    `).join('')}
                                </div>
                            </div>
                        `).join('')
                    : '<div class="text-center text-white/70 py-8">‚úÖ No security issues detected in uploaded files</div>'}
                </div>
            `;
        }

        // Export functionality
        exportBtn.addEventListener('click', () => {
            const report = generateReport();
            const blob = new Blob([report], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `MAESTRO_Audit_Report_${Date.now()}.txt`;
            a.click();
            URL.revokeObjectURL(url);
        });

        function generateReport() {
            return `
MAESTRO AI SECURITY AUDIT REPORT
=================================
Generated: ${new Date().toLocaleString()}
Files Analyzed: ${analysisData.files}

EXECUTIVE SUMMARY
-----------------
Total Findings: ${analysisData.findings.length}
- High Severity: ${analysisData.findings.filter(f => f.severity === 'HIGH').length}
- Medium Severity: ${analysisData.findings.filter(f => f.severity === 'MEDIUM').length}
- Low Severity: ${analysisData.findings.filter(f => f.severity === 'LOW').length}

DETAILED FINDINGS
-----------------
${analysisData.findings.map((f, i) => `
${i + 1}. ${f.threat}
   Severity: ${f.severity}
   File: ${f.file}
   Details: ${f.detail}
   Frameworks: ${f.framework.join(', ')}
`).join('\n')}

RECOMMENDATIONS
---------------
1. Review all HIGH severity findings immediately
2. Implement input validation and sanitization
3. Remove hardcoded credentials
4. Add authentication and authorization controls
5. Implement model access monitoring
6. Regular security audits using MAESTRO framework
7. Follow OWASP AI Top 10 best practices
8. Monitor for MITRE ATLAS threat patterns

---
Generated by MAESTRO AI Security Audit Platform
            `.trim();
        }
    </script>
</body>
</html>